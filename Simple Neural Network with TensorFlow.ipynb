{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad281699",
   "metadata": {},
   "source": [
    "# Simple Neural Network with TensorFlow\n",
    "\n",
    "This code is a simple example of using TensorFlow and scikit-learn to create a neural network model that learns to perform addition on two numbers. Here's a breakdown of what each part of the code does:\n",
    "\n",
    "1. **Imports**:\n",
    "   - `tensorflow` is used for building and training the neural network model.\n",
    "   - `train_test_split` from `sklearn.model_selection` is used to split the dataset into training and testing sets.\n",
    "   - `numpy` is used for numerical operations on arrays.\n",
    "   - `random` from the `random` module is used to generate random numbers.\n",
    "\n",
    "2. **Function `generate_dataset(num_samples, test_size)`**:\n",
    "   - This function generates a dataset of random pairs of numbers (between 0 and 0.5) and their sums.\n",
    "   - `num_samples` is the total number of samples to generate.\n",
    "   - `test_size` is the fraction of the dataset to be used as the test set.\n",
    "   - The dataset is split into training and testing sets using `train_test_split`.\n",
    "\n",
    "3. **Creating the dataset**:\n",
    "   - The function `generate_dataset` is called with 5000 samples, and 30% of them are used as the test set.\n",
    "\n",
    "4. **Building the model**:\n",
    "   - A sequential model is created with two layers:\n",
    "     - The first layer is a dense layer with 10 neurons, an input dimension of 2 (since there are two input numbers), and a sigmoid activation function.\n",
    "     - The second layer is a dense layer with 1 neuron (the output) and a sigmoid activation function.\n",
    "   - The optimizer used is Stochastic Gradient Descent (SGD) with a learning rate of 0.1.\n",
    "   - The model is compiled with the mean squared error (MSE) loss function.\n",
    "\n",
    "5. **Training the model**:\n",
    "   - The model is trained on the training dataset for 100 epochs.\n",
    "\n",
    "6. **Evaluating the model**:\n",
    "   - The model's performance is evaluated on the test set, and the loss is printed.\n",
    "\n",
    "7. **Making predictions**:\n",
    "   - The model is used to predict the sum of two new pairs of numbers: [0.1, 0.2] and [0.2, 0.2].\n",
    "   - The predictions are printed.\n",
    "\n",
    "Overall, this code demonstrates a simple use case of a neural network for a regression task (predicting a continuous value) using TensorFlow and scikit-learn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8962f360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "110/110 [==============================] - 0s 911us/step - loss: 0.0444\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 0s 872us/step - loss: 0.0419\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 0s 870us/step - loss: 0.0412\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 0s 923us/step - loss: 0.0406\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 0s 854us/step - loss: 0.0399\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 0s 863us/step - loss: 0.0393\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 0s 902us/step - loss: 0.0386\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 0s 879us/step - loss: 0.0379\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 0s 891us/step - loss: 0.0372\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 0s 873us/step - loss: 0.0364\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 0s 875us/step - loss: 0.0357\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 0s 895us/step - loss: 0.0349\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 0s 895us/step - loss: 0.0341\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0333\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 0s 955us/step - loss: 0.0325\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0316\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 0s 877us/step - loss: 0.0307\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 0s 863us/step - loss: 0.0298\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 0s 854us/step - loss: 0.0288\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 0s 863us/step - loss: 0.0279\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 0s 854us/step - loss: 0.0269\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 0s 951us/step - loss: 0.0260\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0250\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 0s 890us/step - loss: 0.0240\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 0s 853us/step - loss: 0.0230\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 0s 853us/step - loss: 0.0221\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 0s 859us/step - loss: 0.0211\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 0s 881us/step - loss: 0.0201\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 0s 881us/step - loss: 0.0191\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 0s 865us/step - loss: 0.0182\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 0s 969us/step - loss: 0.0172\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 0s 963us/step - loss: 0.0163\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 0s 864us/step - loss: 0.0154\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 0s 856us/step - loss: 0.0146\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 0s 854us/step - loss: 0.0137\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 0s 919us/step - loss: 0.0129\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 0s 859us/step - loss: 0.0121\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 0s 975us/step - loss: 0.0114\n",
      "Epoch 39/100\n",
      "110/110 [==============================] - 0s 969us/step - loss: 0.0107\n",
      "Epoch 40/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0100\n",
      "Epoch 41/100\n",
      "110/110 [==============================] - 0s 865us/step - loss: 0.0094\n",
      "Epoch 42/100\n",
      "110/110 [==============================] - 0s 855us/step - loss: 0.0087\n",
      "Epoch 43/100\n",
      "110/110 [==============================] - 0s 849us/step - loss: 0.0082\n",
      "Epoch 44/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0076\n",
      "Epoch 45/100\n",
      "110/110 [==============================] - 0s 953us/step - loss: 0.0071\n",
      "Epoch 46/100\n",
      "110/110 [==============================] - 0s 983us/step - loss: 0.0066\n",
      "Epoch 47/100\n",
      "110/110 [==============================] - 0s 969us/step - loss: 0.0062\n",
      "Epoch 48/100\n",
      "110/110 [==============================] - 0s 873us/step - loss: 0.0058\n",
      "Epoch 49/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0054\n",
      "Epoch 50/100\n",
      "110/110 [==============================] - 0s 852us/step - loss: 0.0050\n",
      "Epoch 51/100\n",
      "110/110 [==============================] - 0s 853us/step - loss: 0.0046\n",
      "Epoch 52/100\n",
      "110/110 [==============================] - 0s 859us/step - loss: 0.0043\n",
      "Epoch 53/100\n",
      "110/110 [==============================] - 0s 886us/step - loss: 0.0040\n",
      "Epoch 54/100\n",
      "110/110 [==============================] - 0s 941us/step - loss: 0.0038\n",
      "Epoch 55/100\n",
      "110/110 [==============================] - 0s 886us/step - loss: 0.0035\n",
      "Epoch 56/100\n",
      "110/110 [==============================] - 0s 840us/step - loss: 0.0033\n",
      "Epoch 57/100\n",
      "110/110 [==============================] - 0s 842us/step - loss: 0.0030\n",
      "Epoch 58/100\n",
      "110/110 [==============================] - 0s 862us/step - loss: 0.0028\n",
      "Epoch 59/100\n",
      "110/110 [==============================] - 0s 840us/step - loss: 0.0026\n",
      "Epoch 60/100\n",
      "110/110 [==============================] - 0s 843us/step - loss: 0.0025\n",
      "Epoch 61/100\n",
      "110/110 [==============================] - 0s 840us/step - loss: 0.0023\n",
      "Epoch 62/100\n",
      "110/110 [==============================] - 0s 848us/step - loss: 0.0021\n",
      "Epoch 63/100\n",
      "110/110 [==============================] - 0s 910us/step - loss: 0.0020\n",
      "Epoch 64/100\n",
      "110/110 [==============================] - 0s 910us/step - loss: 0.0019\n",
      "Epoch 65/100\n",
      "110/110 [==============================] - 0s 845us/step - loss: 0.0018\n",
      "Epoch 66/100\n",
      "110/110 [==============================] - 0s 851us/step - loss: 0.0017\n",
      "Epoch 67/100\n",
      "110/110 [==============================] - 0s 844us/step - loss: 0.0016\n",
      "Epoch 68/100\n",
      "110/110 [==============================] - 0s 854us/step - loss: 0.0015\n",
      "Epoch 69/100\n",
      "110/110 [==============================] - 0s 852us/step - loss: 0.0014\n",
      "Epoch 70/100\n",
      "110/110 [==============================] - 0s 895us/step - loss: 0.0013\n",
      "Epoch 71/100\n",
      "110/110 [==============================] - 0s 891us/step - loss: 0.0012\n",
      "Epoch 72/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 73/100\n",
      "110/110 [==============================] - 0s 902us/step - loss: 0.0011\n",
      "Epoch 74/100\n",
      "110/110 [==============================] - 0s 950us/step - loss: 0.0010\n",
      "Epoch 75/100\n",
      "110/110 [==============================] - 0s 902us/step - loss: 9.8095e-04\n",
      "Epoch 76/100\n",
      "110/110 [==============================] - 0s 845us/step - loss: 9.3212e-04\n",
      "Epoch 77/100\n",
      "110/110 [==============================] - 0s 906us/step - loss: 8.8716e-04\n",
      "Epoch 78/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 8.4532e-04\n",
      "Epoch 79/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 8.0679e-04\n",
      "Epoch 80/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 7.7165e-04\n",
      "Epoch 81/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 7.3864e-04\n",
      "Epoch 82/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 7.0888e-04\n",
      "Epoch 83/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 6.8101e-04\n",
      "Epoch 84/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 6.5508e-04\n",
      "Epoch 85/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 6.3147e-04\n",
      "Epoch 86/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 6.0976e-04\n",
      "Epoch 87/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 5.8957e-04\n",
      "Epoch 88/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 5.7093e-04\n",
      "Epoch 89/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 5.5388e-04\n",
      "Epoch 90/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 5.3782e-04\n",
      "Epoch 91/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 5.2322e-04\n",
      "Epoch 92/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 5.0969e-04\n",
      "Epoch 93/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 4.9713e-04\n",
      "Epoch 94/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 4.8573e-04\n",
      "Epoch 95/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 4.7512e-04\n",
      "Epoch 96/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 4.6528e-04\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 0s 854us/step - loss: 4.5624e-04\n",
      "Epoch 98/100\n",
      "110/110 [==============================] - 0s 940us/step - loss: 4.4784e-04\n",
      "Epoch 99/100\n",
      "110/110 [==============================] - 0s 921us/step - loss: 4.4007e-04\n",
      "Epoch 100/100\n",
      "110/110 [==============================] - 0s 895us/step - loss: 4.3297e-04\n",
      "\n",
      "Evaluation on the test set:\n",
      "47/47 - 0s - loss: 3.4014e-04 - 109ms/epoch - 2ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "\n",
      "Predictions:\n",
      "0.1 + 0.2 = 0.2956719398498535\n",
      "0.2 + 0.2 = 0.3960716128349304\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from random import random\n",
    "\n",
    "\n",
    "def generate_dataset(num_samples, test_size):\n",
    "    # build inputs/targets for sum operation: y[0][0] = x[0][0] + x[0][1]\n",
    "    x = np.array([[random()/2 for _ in range(2)] for _ in range(num_samples)])\n",
    "    y = np.array([[i[0] + i[1]] for i in x])\n",
    "\n",
    "    # split dataset into test and training sets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "# create a dataset with 5000 samples\n",
    "x_train, x_test, y_train, y_test = generate_dataset(5000, 0.3)\n",
    "\n",
    "# build model with 3 layers: 2 -> 5 -> 1\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(10, input_dim=2, activation=\"sigmoid\"),\n",
    "  tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# choose optimiser\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "# train model\n",
    "model.fit(x_train, y_train, epochs=100)\n",
    "\n",
    "# evaluate model on test set\n",
    "print(\"\\nEvaluation on the test set:\")\n",
    "model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "# get predictions\n",
    "data = np.array([[0.1, 0.2], [0.2, 0.2]])\n",
    "predictions = model.predict(data)\n",
    "\n",
    "# print predictions\n",
    "print(\"\\nPredictions:\")\n",
    "for d, p in zip(data, predictions):\n",
    "    print(\"{} + {} = {}\".format(d[0], d[1], p[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b2d9ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
